# cytonucs_losses.py - –§–ò–ù–ê–õ–¨–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Å–æ –í–°–ï–ú–ò –ª–æ—Å—Å–∞–º–∏

import tensorflow as tf
import numpy as np
from scipy.ndimage import binary_fill_holes, distance_transform_edt

class CytoNucsLoss:
    """
    –ü–æ–ª–Ω—ã–π loss —Å:
    - StarDist BCE + MAE (—á–µ—Ä–µ–∑ C++)
    - WBR (Within-Boundary Regularization)
    - Containment (geometric + distance field)
    - Consistency (single object, no fragmentation)
    """

    def __init__(self, config):
        self.config = config
        self.ndim = config.ndim
        self.epsilon = 1e-6

        # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–µ—Å–∞
        self.lambda_wbr = config.lambda_wbr
        self.lambda_containment = config.lambda_containment
        self.lambda_consistency = config.lambda_consistency if config.enable_consistency else 0.0

        # –ù–û–í–´–ï –≤–µ—Å–∞ (—Å fallback –Ω–∞ 0 –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã)
        self.lambda_fragmentation = getattr(config, 'lambda_fragmentation', 0.0)
        self.lambda_background_penalty = getattr(config, 'lambda_background_penalty', 0.0)

        self.wbr_warmup_epochs = getattr(config, 'wbr_warmup_epochs', 10)
        self.current_epoch = 0

    def _get_wbr_weight(self):
        """–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ WBR loss"""
        if self.current_epoch < self.wbr_warmup_epochs:
            # Linear warmup: 0 ‚Üí lambda_wbr –∑–∞ wbr_warmup_epochs
            warmup_factor = self.current_epoch / self.wbr_warmup_epochs
            return self.lambda_wbr * warmup_factor
        return self.lambda_wbr

    def __call__(self, y_true_raw, y_pred):
        cfg = self.config

        y_true = self._create_gt_from_instances(y_true_raw)

        # === 1. StarDist Loss (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ===
        loss_nucleus = self._stardist_loss(
            y_true['nucleus_prob'], y_pred['nucleus_prob'],
            y_true['nucleus_dist'], y_pred['nucleus_dist'],
            name='nucleus'
        )

        loss_cytoplasm = self._stardist_loss(
            y_true['cytoplasm_prob'], y_pred['cytoplasm_prob'],
            y_true['cytoplasm_dist'], y_pred['cytoplasm_dist'],
            name='cytoplasm'
        )

        # === 2. WBR (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ===
        wbr_raw = self._wbr_loss(y_pred['nucleus_prob'], y_pred['cytoplasm_prob'])
        warmup_epochs = getattr(cfg, 'wbr_warmup_epochs', 5)
        current_epoch = getattr(self, 'current_epoch', 0)

        if current_epoch < warmup_epochs:
            wbr_factor = current_epoch / warmup_epochs
        else:
            wbr_factor = 1.0

        loss_wbr = self.lambda_wbr * wbr_factor * wbr_raw

        # === 3. Containment (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ===
        loss_containment = self._containment_loss(y_true, y_pred, y_true_raw)

        # ============================================================
        # === 4. –ù–û–í–´–ï LOSSES ===
        # ============================================================

        # 4a. Fragmentation Loss (—à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ peaks –Ω–∞ –æ–¥–Ω–æ–º GT)
        loss_fragmentation = tf.constant(0.0, dtype=tf.float32)
        if self.lambda_fragmentation > 0:
            loss_frag_nuc = self._fragmentation_loss(
                y_pred['nucleus_prob'],
                y_true_raw['nucleus_instances'],
                name='nucleus'
            )
            loss_frag_cyto = self._fragmentation_loss(
                y_pred['cytoplasm_prob'],
                y_true_raw['cytoplasm_instances'],
                name='cytoplasm'
            )
            loss_fragmentation = self.lambda_fragmentation * (loss_frag_nuc + loss_frag_cyto) / 2.0

        # 4b. Background Penalty (—É—Å–∏–ª–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ FP –Ω–∞ —Ñ–æ–Ω–µ)
        loss_background = tf.constant(0.0, dtype=tf.float32)
        if self.lambda_background_penalty > 0:
            loss_bg_nuc = self._background_penalty_loss(
                y_pred['nucleus_prob'],
                y_true['nucleus_prob'],
                name='nucleus'
            )
            loss_bg_cyto = self._background_penalty_loss(
                y_pred['cytoplasm_prob'],
                y_true['cytoplasm_prob'],
                name='cytoplasm'
            )
            loss_background = self.lambda_background_penalty * (loss_bg_nuc + loss_bg_cyto) / 2.0

        # ============================================================
        # === TOTAL LOSS ===
        # ============================================================

        total_loss = (
                cfg.lambda_prob_nucleus * loss_nucleus['bce'] +
                cfg.lambda_dist_nucleus * loss_nucleus['distance'] +
                cfg.lambda_prob_cytoplasm * loss_cytoplasm['bce'] +
                cfg.lambda_dist_cytoplasm * loss_cytoplasm['distance'] +
                loss_wbr +
                self.lambda_containment * loss_containment +
                loss_fragmentation +  # ‚Üê –ù–û–í–û–ï
                loss_background  # ‚Üê –ù–û–í–û–ï
        )

        # Debug
        if not hasattr(self, '_loss_call_count'):
            self._loss_call_count = 0
        self._loss_call_count += 1

        if self._loss_call_count < 10 or self._loss_call_count % 100 == 0:
            tf.print("\n=== LOSS (epoch", current_epoch, ") ===")
            tf.print("  Nucleus BCE:", loss_nucleus['bce'], "| Dist:", loss_nucleus['distance'])
            tf.print("  Cytoplasm BCE:", loss_cytoplasm['bce'], "| Dist:", loss_cytoplasm['distance'])
            tf.print("  WBR:", loss_wbr, "(factor", wbr_factor, ")")
            tf.print("  Containment:", loss_containment)
            if self.lambda_fragmentation > 0:
                tf.print("  Fragmentation:", loss_fragmentation)
            if self.lambda_background_penalty > 0:
                tf.print("  Background Penalty:", loss_background)
            tf.print("  TOTAL:", total_loss)

        return total_loss

    # ============================================================
    # === –°–û–ó–î–ê–ù–ò–ï GT —á–µ—Ä–µ–∑ StarDist C++ ===
    # ============================================================

    def _create_gt_from_instances(self, y_true_raw):
        """
        –í—ã–∑—ã–≤–∞–µ—Ç StarDist C++ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è GT prob/dist maps.
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞–∑–¥–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è nucleus –∏ cytoplasm.
        """
        nucleus_instances = y_true_raw['nucleus_instances']
        cytoplasm_instances = y_true_raw['cytoplasm_instances']

        # === –í–´–ó–û–í StarDist C++ —á–µ—Ä–µ–∑ py_function ===
        nucleus_prob, nucleus_dist = tf.py_function(
            func=lambda m: self._star_dist_wrapper_nucleus(m),
            inp=[nucleus_instances],
            Tout=[tf.float32, tf.float32]
        )

        cytoplasm_prob, cytoplasm_dist = tf.py_function(
            func=lambda m: self._star_dist_wrapper_cytoplasm(m),
            inp=[cytoplasm_instances],
            Tout=[tf.float32, tf.float32]
        )

        # Set shapes
        batch_size = tf.shape(nucleus_instances)[0]

        if self.ndim == 3:
            spatial_shape = nucleus_instances.shape[1:4]
        else:
            spatial_shape = nucleus_instances.shape[1:3]

        nucleus_prob.set_shape([None, *spatial_shape, 1])
        nucleus_dist.set_shape([None, *spatial_shape, self.config.n_rays])
        cytoplasm_prob.set_shape([None, *spatial_shape, 1])
        cytoplasm_dist.set_shape([None, *spatial_shape, self.config.n_rays])

        return {
            'nucleus_prob': nucleus_prob,
            'nucleus_dist': nucleus_dist,
            'cytoplasm_prob': cytoplasm_prob,
            'cytoplasm_dist': cytoplasm_dist
        }

    def _star_dist_wrapper_nucleus(self, instances):
        """Wrapper –¥–ª—è nucleus —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        expected_max_radius = getattr(self.config, 'median_max_dist_nucleus', 20.0)
        return self._star_dist_wrapper_internal(instances, expected_max_radius)

    def _star_dist_wrapper_cytoplasm(self, instances):
        """Wrapper –¥–ª—è cytoplasm —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        expected_max_radius = getattr(self.config, 'median_max_dist_cytoplasm', 50.0)
        return self._star_dist_wrapper_internal(instances, expected_max_radius)

    def _star_dist_wrapper_internal(self, instances, expected_max_radius):
        """
        –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ StarDist C++ (–ö–ê–ö –í train.py!).
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–µ–º RAW PIXEL DISTANCES (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)

        Args:
            instances: instance mask (H, W) or (D, H, W)
            expected_max_radius: –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø (–æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)

        Returns:
            prob_map: probability map [0, 1]
            dist_map: RAW distance map –≤ –ü–ò–ö–°–ï–õ–Ø–•
        """
        from stardist.geometry import star_dist, star_dist3D

        instances = instances.numpy()
        batch_size = instances.shape[0]

        prob_list = []
        dist_list = []

        for b in range(batch_size):
            mask = instances[b]

            # Fill holes (–∫–∞–∫ –≤ train.py!)
            mask_filled = np.zeros_like(mask, dtype=np.int32)
            for label_id in np.unique(mask):
                if label_id == 0:
                    continue
                mask_i = (mask == label_id)
                mask_i_filled = binary_fill_holes(mask_i)
                mask_filled[mask_i_filled] = label_id

            # === –í–´–ó–û–í StarDist C++ (–∫–∞–∫ –≤ train.py!) ===
            if self.ndim == 3:
                dist_map_raw = star_dist3D(mask_filled, self.config.rays, mode='cpp')
            else:
                dist_map_raw = star_dist(mask_filled, self.config.n_rays, mode='cpp')

            # === –ö–†–ò–¢–ò–ß–ù–û: –ë–ï–ó –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò! ===
            # StarDist —Ä–∞–±–æ—Ç–∞–µ—Ç —Å RAW PIXEL DISTANCES
            # Model –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è

            # –¢–æ–ª—å–∫–æ clip –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (—É–±–∏—Ä–∞–µ–º inf/nan)
            dist_map_clean = np.clip(dist_map_raw, 0, 500.0)

            # Prob map —á–µ—Ä–µ–∑ EDT + tanh (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
            prob_map = np.zeros(mask.shape, dtype=np.float32)
            for label_id in np.unique(mask_filled):
                if label_id == 0:
                    continue
                m = (mask_filled == label_id)
                edt = distance_transform_edt(m)
                if edt.max() > 0:
                    prob_map[m] = np.maximum(prob_map[m], np.tanh(edt / edt.max() * 3.0)[m])

            prob_list.append(prob_map[..., np.newaxis])
            dist_list.append(dist_map_clean)  # ‚Üê RAW PIXELS!

        prob_batch = np.stack(prob_list, axis=0)
        dist_batch = np.stack(dist_list, axis=0)

        return prob_batch.astype(np.float32), dist_batch.astype(np.float32)

    # ============================================================
    # === STARDIST LOSS ===
    # ============================================================

    def _stardist_loss(self, prob_true, prob_pred, dist_true, dist_pred, name='object'):
        """
        –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π StarDist loss: BCE + MAE.
        –ò–°–ü–†–ê–í–õ–ï–ù–û: Balanced BCE –¥–ª—è –±–æ—Ä—å–±—ã —Å class imbalance.
        """
        # ============================================================
        # === 1. BALANCED BCE ===
        # ============================================================

        # –ö–†–ò–¢–ò–ß–ù–û: –£–±–∏—Ä–∞–µ–º channel dimension
        prob_true_squeeze = tf.squeeze(prob_true, axis=-1)  # (B, H, W, 1) ‚Üí (B, H, W)
        prob_pred_squeeze = tf.squeeze(prob_pred, axis=-1)

        # –ú–∞—Å–∫–∏ foreground/background
        foreground_mask = tf.cast(prob_true_squeeze > 0.5, tf.float32)  # (B, H, W)
        background_mask = 1.0 - foreground_mask

        # –ö–†–ò–¢–ò–ß–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π API –±–µ–∑ reduction
        # BCE = -(y*log(p) + (1-y)*log(1-p))
        epsilon = 1e-7
        prob_pred_clipped = tf.clip_by_value(prob_pred_squeeze, epsilon, 1.0 - epsilon)

        bce_raw = -(
                prob_true_squeeze * tf.math.log(prob_pred_clipped) +
                (1.0 - prob_true_squeeze) * tf.math.log(1.0 - prob_pred_clipped)
        )  # (B, H, W) - –ø–æ—Ç–æ—á–µ—á–Ω—ã–π BCE –±–µ–∑ reduction

        # –í–µ—Å–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        fg_weight = 1.0
        bg_weight = 0.5 if name == 'cytoplasm' else 1.0

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞ (–≤—Å–µ shape = (B, H, W))
        weight_map = foreground_mask * fg_weight + background_mask * bg_weight
        bce_weighted = bce_raw * weight_map

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–∏–∫—Å–µ–ª–µ–π –ö–ê–ñ–î–û–ì–û –∫–ª–∞—Å—Å–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
        num_fg = tf.reduce_sum(foreground_mask) + self.epsilon
        num_bg = tf.reduce_sum(background_mask) + self.epsilon

        # Balanced loss: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ fg –∏ bg –æ—Ç–¥–µ–ª—å–Ω–æ
        loss_bce_fg = tf.reduce_sum(bce_weighted * foreground_mask) / num_fg
        loss_bce_bg = tf.reduce_sum(bce_weighted * background_mask) / num_bg
        loss_bce = (loss_bce_fg + loss_bce_bg) / 2.0

        # ============================================================
        # === 2. MAE –¥–ª—è distance (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
        # ============================================================

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–°–•–û–î–ù–´–ô prob_true (—Å channel dim) –¥–ª—è distance mask
        foreground_mask_orig = tf.cast(prob_true > 0.5, tf.float32)  # (B, H, W, 1)
        n_rays = tf.shape(dist_true)[-1]

        if self.ndim == 2:
            foreground_mask_exp = tf.tile(foreground_mask_orig, [1, 1, 1, n_rays])
        else:
            foreground_mask_exp = tf.tile(foreground_mask_orig, [1, 1, 1, 1, n_rays])

        dist_error = tf.abs(dist_true - dist_pred)
        weighted_dist_error = dist_error * foreground_mask_exp

        num_fg_pixels = tf.reduce_sum(foreground_mask_orig) + self.epsilon
        loss_distance = tf.reduce_sum(weighted_dist_error) / (
                num_fg_pixels * tf.cast(n_rays, tf.float32) + self.epsilon
        )

        # ============================================================
        # === Debug ===
        # ============================================================

        if not hasattr(self, '_debug_count'):
            self._debug_count = {}
        if name not in self._debug_count:
            self._debug_count[name] = 0
        self._debug_count[name] += 1

        if self._debug_count[name] < 5:
            mean_pred_fg = tf.reduce_sum(prob_pred_squeeze * foreground_mask) / num_fg
            mean_pred_bg = tf.reduce_sum(prob_pred_squeeze * background_mask) / num_bg

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            max_pred_bg = tf.reduce_max(prob_pred_squeeze * background_mask)

            tf.print("\n  [STARDIST LOSS -", name, "]")
            tf.print("    BCE (balanced):     ", loss_bce)
            tf.print("      ‚îî‚îÄ fg component:  ", loss_bce_fg)
            tf.print("      ‚îî‚îÄ bg component:  ", loss_bce_bg)
            tf.print("    Mean prob (fg):     ", mean_pred_fg)
            tf.print("    Mean prob (bg):     ", mean_pred_bg, "‚Üê should be LOW!")
            tf.print("    Max prob (bg):      ", max_pred_bg)
            tf.print("    Dist MAE (fg):      ", loss_distance)

            mean_dist_fg = tf.reduce_sum(dist_pred * foreground_mask_exp) / (
                    tf.reduce_sum(foreground_mask_exp) + self.epsilon
            )
            tf.print("    Mean dist (fg):     ", mean_dist_fg, "px")

        return {'bce': loss_bce, 'distance': loss_distance}

    # ============================================================
    # === WBR LOSS ===
    # ============================================================

    def _wbr_loss(self, nucleus_prob_pred, cytoplasm_prob_pred):
        """
        Within-Boundary Regularization.
        Nucleus –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ cytoplasm.
        """
        nucleus_mask = nucleus_prob_pred
        cytoplasm_inverted = 1.0 - cytoplasm_prob_pred

        # Nucleus predictions OUTSIDE cytoplasm
        nucleus_outside = nucleus_mask * cytoplasm_inverted
        numerator = tf.reduce_sum(nucleus_outside)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ NUCLEUS area
        denominator = tf.reduce_sum(nucleus_mask) + self.epsilon

        ratio = numerator / denominator

        return ratio

    # ============================================================
    # === CONTAINMENT LOSS ===
    # ============================================================

    def _containment_loss(self, y_true, y_pred, y_true_raw):
        """
        Multi-nuclear containment loss:
        1. Geometric: nucleus inside cytoplasm
        2. Distance field: nuc_dist <= cyto_dist
        3. Center separation: multi-nuclear cells –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ —Ü–µ–Ω—Ç—Ä—ã
        """
        if self.lambda_containment == 0:
            return tf.constant(0.0, dtype=tf.float32)

        nuc_prob = y_pred['nucleus_prob']
        cyto_prob = y_pred['cytoplasm_prob']
        nuc_dist = y_pred['nucleus_dist']
        cyto_dist = y_pred['cytoplasm_dist']

        nuc_prob_gt = y_true['nucleus_prob']
        cyto_prob_gt = y_true['cytoplasm_prob']

        # 1. GEOMETRIC CONTAINMENT: nucleus inside cytoplasm
        nuc_outside_cyto = nuc_prob * (1.0 - cyto_prob)
        loss_geometric = tf.reduce_mean(nuc_outside_cyto)

        # 2. DISTANCE FIELD CONTAINMENT
        nuc_fg = tf.cast(nuc_prob_gt > 0.5, tf.float32)
        n_rays = tf.shape(nuc_dist)[-1]

        if self.ndim == 2:
            nuc_fg_exp = tf.tile(nuc_fg, [1, 1, 1, n_rays])
        else:
            nuc_fg_exp = tf.tile(nuc_fg, [1, 1, 1, 1, n_rays])

        distance_violation = tf.nn.relu(nuc_dist - cyto_dist) * nuc_fg_exp
        loss_distance_containment = tf.reduce_mean(distance_violation)

        # 3. CENTER SEPARATION (–¥–ª—è multi-nuclear cells)
        # –ü–æ–ª—É—á–∞–µ–º median_radius –∏–∑ config –∏–ª–∏ –≤—ã—á–∏—Å–ª—è–µ–º
        if hasattr(self.config, 'median_radius_train') and self.config.median_radius_train is not None:
            median_radius = self.config.median_radius_train
        else:
            # Fallback: –≤—ã—á–∏—Å–ª—è–µ–º –∏–∑ GT
            nuc_dist_fg = y_true['nucleus_dist'] * nuc_fg_exp
            num_fg = tf.reduce_sum(nuc_fg_exp) + self.epsilon
            median_radius = tf.reduce_sum(nuc_dist_fg) / num_fg
            median_radius = tf.maximum(median_radius, 1.0)

        loss_separation = self._compute_center_separation(
            nuc_prob=nuc_prob,
            cyto_prob_gt=cyto_prob_gt,
            nuc_prob_gt=nuc_prob_gt,
            median_radius=median_radius
        )

        # COMBINE
        w_geometric = getattr(self.config, 'w_containment_geometric', 1.0)
        w_distance = getattr(self.config, 'w_containment_distance', 0.5)
        w_separation = getattr(self.config, 'w_center_separation', 0.2)

        total_containment_loss = (
            w_geometric * loss_geometric +
            w_distance * loss_distance_containment +
            w_separation * loss_separation
        )

        return total_containment_loss

    # ============================================================
    # === FRAGMENTATION LOSS (Pure TensorFlow) ===
    # ============================================================

    def _fragmentation_loss(self, prob_pred, instances_gt, name='object'):
        """
        –®—Ç—Ä–∞—Ñ—É–µ—Ç –∑–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö peaks –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ GT –æ–±—ä–µ–∫—Ç–∞.
        –ò–°–ü–†–ê–í–õ–ï–ù–û: Pure TensorFlow –±–µ–∑ py_function –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å @tf.function

        –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:
        1. –ù–∞—Ö–æ–¥–∏–º peaks –≤ probability map
        2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ GT –æ–±—ä–µ–∫—Ç–∞ —Å—á–∏—Ç–∞–µ–º —Å—É–º–º–∞—Ä–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å peaks
        3. –®—Ç—Ä–∞—Ñ—É–µ–º, –µ—Å–ª–∏ —Å—É–º–º–∞—Ä–Ω–∞—è prob —Å–∏–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—É—é (1.0)

        Args:
            prob_pred: (B, H, W, 1) –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
            instances_gt: (B, H, W) GT instance mask
            name: 'nucleus' –∏–ª–∏ 'cytoplasm'

        Returns:
            loss: —Å–∫–∞–ª—è—Ä, —à—Ç—Ä–∞—Ñ –∑–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        """

        prob_squeeze = tf.squeeze(prob_pred, axis=-1)  # (B, H, W)

        # ============================================================
        # 1. –ù–∞—Ö–æ–¥–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∞–∫—Å–∏–º—É–º—ã (peaks)
        # ============================================================

        kernel_size = 5 if self.ndim == 2 else 5

        if self.ndim == 2:
            prob_maxpool = tf.nn.max_pool2d(
                prob_pred,
                ksize=kernel_size,
                strides=1,
                padding='SAME'
            )
        else:
            prob_maxpool = tf.nn.max_pool3d(
                prob_pred,
                ksize=kernel_size,
                strides=1,
                padding='SAME'
            )

        prob_maxpool_squeeze = tf.squeeze(prob_maxpool, axis=-1)

        # Peaks: –≥–¥–µ prob = maxpool –∏ prob > 0.3
        is_peak = tf.logical_and(
            tf.abs(prob_squeeze - prob_maxpool_squeeze) < 0.01,
            prob_squeeze > 0.3
        )

        # Peak strength (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤ —Ç–æ—á–∫–∞—Ö peaks)
        peak_strength = tf.where(is_peak, prob_squeeze, 0.0)

        # ============================================================
        # 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ GT –æ–±—ä–µ–∫—Ç–∞ —Å—á–∏—Ç–∞–µ–º —Å—É–º–º—É peak strengths
        # ============================================================

        instances_gt_float = tf.cast(instances_gt, tf.float32)

        # –ü–æ–ª—É—á–∞–µ–º unique labels (–±–µ–∑ 0)
        # –ö–†–ò–¢–ò–ß–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º tf ops –≤–º–µ—Å—Ç–æ numpy

        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥: –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ labels –æ—Ç 1 –¥–æ max_label
        max_label = tf.cast(tf.reduce_max(instances_gt_float), tf.int32)
        max_label = tf.minimum(max_label, 200)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

        penalties = []

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ label
        for label_id in range(1, 201):  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è @tf.function
            label_id_float = tf.cast(label_id, tf.float32)

            # –ú–∞—Å–∫–∞ –æ–±—ä–µ–∫—Ç–∞ —Å —ç—Ç–∏–º label
            obj_mask = tf.equal(instances_gt_float, label_id_float)  # (B, H, W)
            obj_mask_float = tf.cast(obj_mask, tf.float32)

            # –°—É–º–º–∞ area –æ–±—ä–µ–∫—Ç–∞
            obj_area = tf.reduce_sum(obj_mask_float)

            # Skip –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ—Ç
            obj_exists = tf.greater(obj_area, 0.5)

            # –°—É–º–º–∞ peak strengths –≤–Ω—É—Ç—Ä–∏ –æ–±—ä–µ–∫—Ç–∞
            peaks_in_obj = peak_strength * obj_mask_float
            total_peak_strength = tf.reduce_sum(peaks_in_obj)

            # –ò–¥–µ–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = 1.0 (–æ–¥–∏–Ω peak —Å prob=1.0)
            # –ï—Å–ª–∏ total > 1.5, –∑–Ω–∞—á–∏—Ç –µ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            fragmentation_penalty = tf.nn.relu(total_peak_strength - 1.5)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º penalty —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            penalty = tf.where(obj_exists, fragmentation_penalty, 0.0)

            penalties.append(penalty)

        # –°—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º labels
        mean_penalty = tf.reduce_mean(tf.stack(penalties))

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ batch size –ò –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        batch_size = tf.cast(tf.shape(prob_squeeze)[0], tf.float32)

        # –ö–†–ò–¢–ò–ß–ù–û: –î–µ–ª–∏–º –Ω–∞ –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∞
        mean_penalty = mean_penalty / (batch_size * 100.0 + self.epsilon)  # ‚Üê –î–û–ë–ê–í–õ–ï–ù–û /100

        return mean_penalty

    # ============================================================
    # === BACKGROUND PENALTY LOSS (—É–∂–µ Pure TensorFlow) ===
    # ============================================================

    def _background_penalty_loss(self, prob_pred, prob_gt, name='object'):
        """
        –£—Å–∏–ª–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ –≤—ã—Å–æ–∫–∏–µ predictions –Ω–∞ —Ñ–æ–Ω–µ.
        Pure TensorFlow - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —É–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞.
        """

        prob_pred_squeeze = tf.squeeze(prob_pred, axis=-1)  # (B, H, W)
        prob_gt_squeeze = tf.squeeze(prob_gt, axis=-1)

        # –§–æ–Ω = –≥–¥–µ GT prob < 0.1 (—á–∏—Å—Ç—ã–π background)
        background_mask = tf.cast(prob_gt_squeeze < 0.1, tf.float32)

        # Predictions –Ω–∞ —Ñ–æ–Ω–µ
        pred_on_background = prob_pred_squeeze * background_mask

        # –ö–í–ê–î–†–ê–¢–ò–ß–ù–´–ô —à—Ç—Ä–∞—Ñ
        penalty = tf.square(pred_on_background)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏—Ö prob (> 0.5)
        high_confidence_mask = tf.cast(pred_on_background > 0.5, tf.float32)
        extra_penalty = high_confidence_mask * tf.square(pred_on_background) * 2.0

        total_penalty = penalty + extra_penalty

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏ —Ñ–æ–Ω–∞
        num_bg_pixels = tf.reduce_sum(background_mask) + self.epsilon
        mean_penalty = tf.reduce_sum(total_penalty) / num_bg_pixels

        return mean_penalty


    def _compute_center_separation(self, nuc_prob, cyto_prob_gt, nuc_prob_gt, median_radius):
        """
        Ensure nucleus centers are well-separated within same cytoplasm.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç max-pooling –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤.
        """
        # Fixed kernel size (—É–ø—Ä–æ—â–µ–Ω–∏–µ –¥–ª—è TensorFlow eager mode)
        kernel_size_fixed = 9 if self.ndim == 2 else 7

        if self.ndim == 2:
            nuc_maxpool = tf.nn.max_pool2d(
                nuc_prob,
                ksize=kernel_size_fixed,
                strides=1,
                padding='SAME'
            )
        else:
            nuc_maxpool = tf.nn.max_pool3d(
                nuc_prob,
                ksize=kernel_size_fixed,
                strides=1,
                padding='SAME'
            )

        # Peaks: where prob ‚âà maxpool and prob > threshold
        is_peak = tf.cast(
            tf.logical_and(
                tf.abs(nuc_prob - nuc_maxpool) < 0.05,
                nuc_prob > 0.5
            ),
            tf.float32
        )

        cyto_fg_gt = tf.cast(cyto_prob_gt > 0.5, tf.float32)
        nuc_fg_gt = tf.cast(nuc_prob_gt > 0.5, tf.float32)

        # Peaks within cytoplasm
        peaks_in_cyto = is_peak * cyto_fg_gt

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ per-batch
        if self.ndim == 2:
            reduction_axes = [1, 2, 3]
            expected_area_per_nucleus = 3.14159 * tf.square(median_radius)
        else:
            reduction_axes = [1, 2, 3, 4]
            expected_area_per_nucleus = 4.0 / 3.0 * 3.14159 * tf.pow(median_radius, 3.0)

        gt_nucleus_area = tf.reduce_sum(nuc_fg_gt, axis=reduction_axes)
        cyto_area = tf.reduce_sum(cyto_fg_gt, axis=reduction_axes) + self.epsilon

        expected_num_nuclei = gt_nucleus_area / (expected_area_per_nucleus + self.epsilon)
        target_density = expected_num_nuclei / cyto_area

        num_peaks = tf.reduce_sum(peaks_in_cyto, axis=reduction_axes)
        peak_density = num_peaks / cyto_area

        # L1 loss –∫ GT-based target density
        density_error = tf.abs(peak_density - target_density)

        # Tolerance ¬±20%
        tolerance = target_density * 0.2 + self.epsilon
        penalty = tf.nn.relu(density_error - tolerance)

        return tf.reduce_mean(penalty)

    # ============================================================
    # === CONSISTENCY LOSS ===
    # ============================================================

    def _consistency_loss(self, prob_pred, prob_gt):
        """
        Consistency within single GT object.
        Penalizes high variance of predicted prob within GT foreground.
        –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é –æ–±—ä–µ–∫—Ç–æ–≤.
        """
        if self.ndim == 2:
            prob_pred_map = tf.squeeze(prob_pred, axis=-1)  # (B, H, W)
            fg_mask = tf.squeeze(prob_gt, axis=-1)
        else:
            prob_pred_map = tf.squeeze(prob_pred, axis=-1)  # (B, H, W, D)
            fg_mask = tf.squeeze(prob_gt, axis=-1)

        fg_mask = tf.cast(fg_mask > 0.5, tf.float32)

        # Masked predictions
        prob_on_fg = prob_pred_map * fg_mask

        min_fg_pixels = 10.0 if self.ndim == 2 else 50.0

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
        if self.ndim == 2:
            num_fg = tf.reduce_sum(fg_mask, axis=[1, 2])  # (B,)
            mean_prob = tf.reduce_sum(prob_on_fg, axis=[1, 2]) / (num_fg + self.epsilon)

            prob_centered = (prob_pred_map - tf.expand_dims(tf.expand_dims(mean_prob, -1), -1)) * fg_mask
            variance = tf.reduce_sum(tf.square(prob_centered), axis=[1, 2]) / (num_fg + self.epsilon)
        else:  # 3D
            num_fg = tf.reduce_sum(fg_mask, axis=[1, 2, 3])
            mean_prob = tf.reduce_sum(prob_on_fg, axis=[1, 2, 3]) / (num_fg + self.epsilon)

            prob_centered = (
                prob_pred_map -
                tf.expand_dims(tf.expand_dims(tf.expand_dims(mean_prob, -1), -1), -1)
            ) * fg_mask
            variance = tf.reduce_sum(tf.square(prob_centered), axis=[1, 2, 3]) / (num_fg + self.epsilon)

        # Adaptive threshold –ø–æ —Ä–∞–∑–º–µ—Ä—É –æ–±—ä–µ–∫—Ç–∞
        size_factor = tf.minimum(num_fg / 200.0, 1.0)
        adaptive_threshold = 0.15 - 0.05 * size_factor

        # Penalty –∑–∞ –≤—ã—Å–æ–∫—É—é variance
        penalty = tf.nn.relu(variance - adaptive_threshold)

        # –ú–∞—Å–∫–∞ –¥–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        valid_mask = tf.cast(num_fg >= min_fg_pixels, tf.float32)

        weighted_penalty = penalty * valid_mask
        num_valid = tf.reduce_sum(valid_mask) + self.epsilon

        return tf.reduce_sum(weighted_penalty) / num_valid


# ============================================================
# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò (numpy, –¥–ª—è monitoring) ===
# ============================================================

def compute_nucleus_cell_assignments(nucleus_instances, cytoplasm_instances, max_distance=100.0):
    """Smart overlap-based assignment –¥–ª—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤"""
    from skimage.measure import regionprops
    from scipy.spatial.distance import cdist
    from collections import defaultdict

    if nucleus_instances.shape != cytoplasm_instances.shape:
        min_shape = tuple(min(n, c) for n, c in zip(nucleus_instances.shape, cytoplasm_instances.shape))
        nucleus_instances = nucleus_instances[tuple(slice(0, s) for s in min_shape)]
        cytoplasm_instances = cytoplasm_instances[tuple(slice(0, s) for s in min_shape)]

    nuc_props = {p.label: p for p in regionprops(nucleus_instances)}
    cyto_props = {p.label: p for p in regionprops(cytoplasm_instances)}

    assignments = {}
    unassigned = []

    # –°–¢–†–ê–¢–ï–ì–ò–Ø 1: Maximum overlap
    for nuc_id, nuc_prop in nuc_props.items():
        nuc_mask = (nucleus_instances == nuc_id)

        overlaps = {}
        for cyto_id in cyto_props.keys():
            cyto_mask = (cytoplasm_instances == cyto_id)
            overlap_pixels = np.logical_and(nuc_mask, cyto_mask).sum()
            if overlap_pixels > 0:
                overlaps[cyto_id] = overlap_pixels

        if len(overlaps) > 0:
            best_cell = max(overlaps, key=overlaps.get)
            best_overlap = overlaps[best_cell]
            overlap_fraction = best_overlap / nuc_mask.sum()

            if overlap_fraction > 0.01:
                assignments[int(nuc_id)] = int(best_cell)
                continue

    # –°–¢–†–ê–¢–ï–ì–ò–Ø 2: Proximity
    unassigned_nuclei = [nid for nid in nuc_props.keys() if int(nid) not in assignments]

    if len(unassigned_nuclei) > 0 and len(cyto_props) > 0:
        cyto_centers = np.array([p.centroid for p in cyto_props.values()])
        cyto_ids = list(cyto_props.keys())

        for nuc_id in unassigned_nuclei:
            nuc_center = nuc_props[nuc_id].centroid
            dists = cdist([nuc_center], cyto_centers)[0]
            nearest_idx = np.argmin(dists)

            if dists[nearest_idx] <= max_distance:
                assignments[int(nuc_id)] = int(cyto_ids[nearest_idx])
            else:
                unassigned.append(int(nuc_id))
    else:
        unassigned.extend([int(nid) for nid in unassigned_nuclei])

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"  Assigned: {len(assignments)}/{len(nuc_props)} (overlap+proximity)")

    cell_to_nuclei = defaultdict(list)
    for nuc_id, cell_id in assignments.items():
        cell_to_nuclei[cell_id].append(nuc_id)

    multi_nuclear = {cid: len(nids) for cid, nids in cell_to_nuclei.items() if len(nids) > 1}
    if len(multi_nuclear) > 0:
        print(f"    üî¨ Multi-nuclear: {len(multi_nuclear)} cells (max {max(multi_nuclear.values())} nuclei/cell)")

    stats = {'assigned': len(assignments), 'unassigned': len(unassigned)}

    assert len(assignments) <= len(nuc_props), f"Assignments overflow!"

    return assignments, unassigned, stats